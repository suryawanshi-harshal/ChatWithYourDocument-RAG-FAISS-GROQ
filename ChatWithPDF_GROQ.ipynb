{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"your_GROQ_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_document(filepath):\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "\n",
    "    if file_extension.lower() == '.pdf':\n",
    "        loader = PyPDFLoader(filepath)\n",
    "    elif file_extension.lower() == '.docx':\n",
    "        loader = UnstructuredWordDocumentLoader(filepath)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format: {}\".format(file_extension))\n",
    "    \n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "filepath = \"Your_file_path\"\n",
    "docs = load_document(filepath)\n",
    "\n",
    "# Set up the text splitter\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# Split the document into chunks\n",
    "splitted_docs = r_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# Create a custom embedding function\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name='all-mpnet-base-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode(text).tolist()\n",
    "\n",
    "# Initialize the embedding function\n",
    "embeddings = SentenceTransformerEmbeddings()\n",
    "\n",
    "# Create the FAISS index\n",
    "vector_store = FAISS.from_documents(splitted_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key = \"your_key\",\n",
    "    model_name = 'mixtral-8x7b-32768'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following quesion based on the retrieved context.\n",
    "    Think step by step. Keep your answers brief. Reply with \"I'm not sure how to answer that. Please provide more context and try simplyfying your question.\" when you don't have an answer for any question. \n",
    "    Do not respond with wrong answers. All answers should come form the retireved context.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm_chain = create_stuff_documents_chain(\n",
    "    llm, \n",
    "    prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever, \n",
    "    llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "\n",
    "def format_response(response):\n",
    "    # Split the response into paragraphs\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', response)\n",
    "    \n",
    "    formatted_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        # Check if the paragraph is a numbered list\n",
    "        if re.match(r'\\d+\\.', paragraph):\n",
    "            # Split the numbered list into items\n",
    "            items = re.split(r'\\n\\s*(\\d+\\.)', paragraph)\n",
    "            formatted_items = []\n",
    "            for i in range(1, len(items), 2):\n",
    "                number = items[i]\n",
    "                text = items[i+1] if i+1 < len(items) else \"\"\n",
    "                wrapped_text = textwrap.fill(text.strip(), width=76, subsequent_indent='    ')\n",
    "                formatted_items.append(f\"{number} {wrapped_text}\")\n",
    "            formatted_paragraphs.append('\\n'.join(formatted_items))\n",
    "        else:\n",
    "            # Regular paragraph\n",
    "            wrapped = textwrap.fill(paragraph.strip(), width=80)\n",
    "            formatted_paragraphs.append(wrapped)\n",
    "    \n",
    "    # Join paragraphs with double line breaks\n",
    "    formatted_response = '\\n\\n'.join(formatted_paragraphs)\n",
    "    \n",
    "    return formatted_response\n",
    "\n",
    "# Use the function\n",
    "prompt = \"Detailed steps to create a warehouse. Explain any required permissions too.\"\n",
    "response = retrieval_chain.invoke({\"input\": prompt})\n",
    "formatted_answer = format_response(response['answer'])\n",
    "print(formatted_answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
